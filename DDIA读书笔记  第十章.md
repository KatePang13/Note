## DDIA读书笔记  第十章

**物化( Materialization)**

将中间状态写到文件的过程称为物化

- **增量Stream**   Unix pipi    
  - 通过一个很小的内存缓冲区，将输出增量地已流的形式传递给下一个输入

- **完全物化**   MapReduce
  - 一个MapReduce 作业必须将结果保存到HDFS/GFS
  - 缺点： 
    - 作业之间严格串行化
    - 后面的Mapper 通常是多余的，只是机械的透传 上一个作业的 Reducer 的输出
    - 将中间状态存储在DFS，意味着要在多个节点备份，浪费存储



**数据流引擎**

为了解决MapReduce的上述问题，很多新的分布式批处理引擎相继出现，最出名的有 Spark, Tez, Flink。它们的设计有很大的区别，但是有一个共同点：

**把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业**

与MapReduce的比较

- 相同点：

  - 在一条线上通过反复调用用户定义的函数，一次处理一条记录
  - 通过输入分区来实现并行化
  - 通过网络将一个函数的输出复制到另一个函数的输入

- 不同点

  - 子流程之间不再严格地扮演Map和Reduce的角色
  - 已更灵活的方式进行组合
  - 每个函数称为一个 算子 （operator）

  

  引擎为算子之间的连接提供了多种选项 【？？】

  - 按 key 重新分区并排列，就像 MapReduce的 **shuffle** 
  - 接收多个输入，以相同的方式进行分区，但是跳过排序
  - 对于广播散列连接，可以将一个算子的输出，发送到连接算子的所有分区。

  

  

  

### 总结

在本章中，我们探索了批处理的主题。我们首先看到了诸如awk，grep和sort之类的Unix工具，然后我们看到了这些工具的设计理念是如何应用到MapReduce和更近的数据流引擎中的。一些设计原则包括：输入是不可变的，输出是为了作为另一个（仍未知的）程序的输入，而复杂的问题是通过编写“做好一件事”的小工具来解决的。

 在Unix世界中，允许程序与程序组合的统一接口是文件与管道；在MapReduce中，该接口是一个分布式文件系统。我们看到数据流引擎添加了自己的管道式数据传输机制，以避免将中间状态物化至分布式文件系统，但作业的初始输入和最终输出通常仍是HDFS。

 分布式批处理框架需要解决的两个主要问题是：

***分区***

 在MapReduce中，Mapper根据输入文件块进行分区。Mapper的输出被重新分区，排序，并合并到可配置数量的Reducer分区中。这一过程的目的是把所有的**相关**数据（例如带有相同键的所有记录）都放在同一个地方。

 后MapReduce时代的数据流引擎若非必要会尽量避免排序，但它们也采取了大致类似的分区方法。

***容错***

 MapReduce经常写入磁盘，这使得从单个失败的任务恢复很轻松，无需重新启动整个作业，但在无故障的情况下减慢了执行速度。数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态，这意味着如果节点发生故障，则需要重算更多的数据。确定性算子减少了需要重算的数据量。

 我们讨论了几种MapReduce的连接算法，其中大多数也在MPP数据库和数据流引擎内部使用。它们也很好地演示了分区算法是如何工作的：

***排序合并连接***

 每个参与连接的输入都通过一个提取连接键的Mapper。通过分区，排序和合并，具有相同键的所有记录最终都会进入相同的Reducer调用。这个函数能输出连接好的记录。

***广播散列连接***

 两个连接输入之一很小，所以它并没有分区，而且能被完全加载进一个哈希表中。因此，你可以为连接输入大端的每个分区启动一个Mapper，将输入小端的散列表加载到每个Mapper中，然后扫描大端，一次一条记录，并为每条记录查询散列表。

***分区散列连接***

 如果两个连接输入以相同的方式分区（使用相同的键，相同的散列函数和相同数量的分区），则可以独立地对每个分区应用散列表方法。

 分布式批处理引擎有一个刻意限制的编程模型：回调函数（比如Mapper和Reducer）被假定是无状态的，而且除了指定的输出外，必须没有任何外部可见的副作用。这一限制允许框架在其抽象下隐藏一些困难的分布式系统问题：当遇到崩溃和网络问题时，任务可以安全地重试，任何失败任务的输出都被丢弃。如果某个分区的多个任务成功，则其中只有一个能使其输出实际可见。

 得益于这个框架，你在批处理作业中的代码无需操心实现容错机制：框架可以保证作业的最终输出与没有发生错误的情况相同，也许不得不重试各种任务。在线服务处理用户请求，并将写入数据库作为处理请求的副作用，比起在线服务，批处理提供的这种可靠性语义要强得多。

 批处理作业的显著特点是，它读取一些输入数据并产生一些输出数据，但不修改输入—— 换句话说，输出是从输入衍生出的。最关键的是，输入数据是**有界的（bounded）**：它有一个已知的，固定的大小（例如，它包含一些时间点的日志文件或数据库内容的快照）。因为它是有界的，一个作业知道自己什么时候完成了整个输入的读取，所以一个工作在做完后，最终总是会完成的。

 在下一章中，我们将转向流处理，其中的输入是**无界的（unbounded）** —— 也就是说，你还有活儿要干，然而它的输入是永无止境的数据流。在这种情况下，作业永无完成之日。因为在任何时候都可能有更多的工作涌入。我们将看到，在某些方面上，流处理和批处理是相似的。但是关于无尽数据流的假设也对我们构建系统的方式产生了很多改变。

